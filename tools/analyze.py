import os
import json
import pandas as pd
from typing import List, Dict
from collections import defaultdict
from threading import Lock
from concurrent.futures import ThreadPoolExecutor, as_completed
from agents.video_analyst import VideoAnalyst
from agents.image_analyst import ImageAnalyst
from agents.text_analyst import TextAnalyst
from agents.user_profile_generator import UserProfileGenerator

def _convert_user_id(user_id, dataset):
    """Convert internal user_id to real user_id using user_map.json"""
    if dataset == 'bilibili':
        user_map_path = "SSLRec/datasets/general_cf/bilibili/user_map.json"
    elif dataset == 'douban':
        user_map_path = "SSLRec/datasets/general_cf/douban/user_map.json"
    elif dataset == 'redbook':
        user_map_path = "SSLRec/datasets/general_cf/redbook/user_map.json"
    elif dataset == 'hupu':
        user_map_path = "SSLRec/datasets/general_cf/hupu/user_map.json"
    else:
        # For unknown datasets, assume user_id is already real
        return str(user_id)

    try:
        with open(user_map_path, 'r', encoding='utf-8') as f:
            user_map = json.load(f)

        # user_id could be string or int
        real_user_id = user_map.get(str(user_id))
        if real_user_id:
            print(f"ğŸ”„ Converted user_id {user_id} -> {real_user_id}")
            return real_user_id
        else:
            print(f"âš ï¸  User_id {user_id} not found in user_map")
            return None

    except FileNotFoundError:
        print(f"âš ï¸  User mapping file not found: {user_map_path}")
        # Fallback: assume user_id is already real
        return str(user_id)
    except json.JSONDecodeError:
        print(f"âš ï¸  Invalid JSON in user mapping file: {user_map_path}")
        return str(user_id)

def get_file_type(filename):
    """Determine file type based on file extension"""
    _, ext = os.path.splitext(filename)
    ext = ext.lower()

    video_extensions = ['.mp4']
    image_extensions = ['.jpg', '.jpeg', '.png']
    text_extensions = ['.txt']

    if ext in video_extensions:
        return "video"
    elif ext in image_extensions:
        return "image"
    elif ext in text_extensions:
        return "text"
    else:
        return "unknown"


def get_chronological_order(user_id, convert_user_id=True):
    """Get chronological order of items based on all CSV files for the user

    Args:
        user_id: User ID (could be internal or real depending on convert_user_id)
        convert_user_id: Whether to convert user_id to real_user_id (default: True for backward compatibility)
    """
    dataset = os.getenv("DATASET")
    if not dataset:
        print("âš ï¸  DATASET environment variable not set")
        return []

    # Convert internal user_id to real user_id if needed
    if convert_user_id:
        real_user_id = _convert_user_id(user_id, dataset)
        if not real_user_id:
            print(f"âš ï¸  Could not convert user_id {user_id} to real user_id")
            return []
        user_dataset_path = f"dataset/{dataset}/{real_user_id}"
        print(f"ğŸ” Processing dataset: {dataset} for user: {user_id} (real_id: {real_user_id})")
    else:
        # user_id is already real_user_id, no conversion needed
        user_dataset_path = f"dataset/{dataset}/{user_id}"
        print(f"ğŸ” Processing dataset: {dataset} for user: {user_id}")

    if not os.path.exists(user_dataset_path):
        print(f"âš ï¸  User dataset directory not found: {user_dataset_path}")
        return []

    try:
        # Dataset-specific column mapping
        dataset_config = {
            'bilibili': {
                'item_id_col': 'bvid',
                'time_col': 'fav_time',
                'required_cols': ['bvid', 'fav_time']
            },
            'douban': {
                'item_id_col': 'doubanID',  # Douban uses doubanID as unique identifier
                'time_col': 'fav_time',
                'required_cols': ['doubanID', 'fav_time']  # fav_time is optional for douban
            },
            'redbook': {
                'item_id_col': 'redbookID',  # RedBook uses redbookID as unique identifier
                'time_col': 'fav_time',
                'required_cols': ['redbookID', 'fav_time']  # fav_time is optional for redbook
            },
            'hupu': {
                'item_id_col': 'hupuID',  # Hupu uses hupuID as unique identifier
                'time_col': 'fav_time',
                'required_cols': ['hupuID', 'fav_time']  # fav_time is optional for hupu
            }
        }

        # Get configuration for current dataset
        config = dataset_config.get(dataset)
        if not config:
            print(f"âš ï¸  Unsupported dataset: {dataset}")
            return []

        item_id_col = config['item_id_col']
        time_col = config['time_col']
        required_cols = config['required_cols']

        # Find all CSV files in the user directory
        csv_files = []
        for file in os.listdir(user_dataset_path):
            if file.endswith('.csv'):
                csv_files.append(os.path.join(user_dataset_path, file))

        if not csv_files:
            print(f"âš ï¸  No CSV files found in: {user_dataset_path}")
            return []

        print(f"ğŸ“ Found {len(csv_files)} CSV file(s) for user {user_id} in {dataset} dataset")

        # Read and combine all CSV files
        all_dataframes = []
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file)

                # Check if required columns exist
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    print(f"  âš ï¸  Missing columns {missing_cols} in {os.path.basename(csv_file)}")
                    continue

                # Extract only the required columns
                if time_col in df.columns:
                    df_subset = df[[item_id_col, time_col]].copy()
                    # Rename columns to standard names for processing
                    df_subset = df_subset.rename(columns={
                        item_id_col: 'item_id',
                        time_col: 'timestamp'
                    })
                else:
                    # If time column doesn't exist, create dummy timestamps
                    df_subset = df[[item_id_col]].copy()
                    df_subset = df_subset.rename(columns={item_id_col: 'item_id'})
                    # Use row index as dummy timestamp (reverse order for newest first)
                    df_subset['timestamp'] = range(len(df_subset)-1, -1, -1)
                    print(f"  â„¹ï¸  Using dummy timestamps for {os.path.basename(csv_file)}")

                all_dataframes.append(df_subset)
                print(f"  âœ… Loaded {len(df_subset)} items from {os.path.basename(csv_file)}")

            except Exception as e:
                print(f"  âš ï¸  Error reading {os.path.basename(csv_file)}: {e}")

        if not all_dataframes:
            print(f"âš ï¸  No valid CSV data found for user {user_id}")
            return []

        # Combine all dataframes
        combined_df = pd.concat(all_dataframes, ignore_index=True)

        # Remove duplicates (same item might appear in multiple folders)
        combined_df = combined_df.drop_duplicates(subset=['item_id'])

        # Sort by timestamp in descending order (newest first)
        # Handle both numeric and non-numeric timestamps
        try:
            # Try to convert to numeric timestamps
            combined_df['timestamp'] = pd.to_numeric(combined_df['timestamp'], errors='coerce')
            # Fill NaN values with 0 for sorting
            combined_df['timestamp'] = combined_df['timestamp'].fillna(0)
            df_sorted = combined_df.sort_values('timestamp', ascending=False)
        except Exception as e:
            print(f"  âš ï¸  Error sorting by timestamp: {e}, using original order")
            df_sorted = combined_df

        print(f"ğŸ“… Total {len(df_sorted)} unique items in chronological order for {dataset} dataset")

        # Return list of item_id in chronological order (newest to oldest)
        return df_sorted['item_id'].tolist()

    except Exception as e:
        print(f"âš ï¸  Error processing CSV files for user {user_id}: {e}")
        return []


def _load_item_mapping():
    """Load item mapping from item ID to title based on dataset type"""
    dataset = os.getenv("DATASET", "bilibili")

    # Configuration for dataset mapping files
    dataset_mapping_config = {
        'douban': {'file': 'douban_mapping.json', 'name': 'Douban'},
        'bilibili': {'file': 'bilibili_mapping.json', 'name': 'Bilibili'},
        'redbook': {'file': 'redbook_mapping.json', 'name': 'Redbook'},
        'hupu': {'file': 'hupu_mapping.json', 'name': 'Hupu'}
    }

    config = dataset_mapping_config.get(dataset)
    if not config:
        print(f"âš ï¸  No mapping file configured for dataset: {dataset}")
        return {}

    mapping_file = config['file']
    mapping_name = config['name']

    if os.path.exists(mapping_file):
        try:
            with open(mapping_file, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
            print(f"âœ… Loaded {len(mapping)} items from {mapping_name} mapping")
            return mapping
        except Exception as e:
            print(f"âš ï¸  Error loading {mapping_name} mapping: {e}")
            return {}
    else:
        print(f"âš ï¸  {mapping_name} mapping file not found: {mapping_file}")
        return {}

def _get_item_title(item_id, item_mapping=None):
    """Get item title from item ID using mapping file (supports both old and new enhanced formats)"""
    if item_mapping is None:
        item_mapping = _load_item_mapping()

    dataset = os.getenv("DATASET", "bilibili")

    # Helper function to extract title from mapping data
    def extract_title(mapping_data):
        if isinstance(mapping_data, dict):
            # New enhanced format: {"title": "...", "content": "...", ...}
            return mapping_data.get('title', item_id)
        elif isinstance(mapping_data, str):
            # Old format: just the title string
            return mapping_data
        else:
            return item_id
    mapping_data = item_mapping.get(item_id)
    if mapping_data:
        return extract_title(mapping_data)

    # Fallback to item_id if no title found
    return item_id

def format_analysis_to_prompt(analysis_data, item_name, item_mapping=None):
    """Format analysis results into natural language prompt"""
    # Get title from item ID
    item_title = _get_item_title(item_name, item_mapping)
    prompt_parts = [f"## Note: {item_title}\n"]

    # Process text content
    if "text" in analysis_data and analysis_data["text"]:
        prompt_parts.append("### Text Content:")
        for idx, text_analysis in analysis_data["text"].items():
            prompt_parts.append(f"- {text_analysis}")
        prompt_parts.append("")

    # Process image content
    if "image" in analysis_data and analysis_data["image"]:
        prompt_parts.append("### Image Content:")
        for idx, image_analysis in analysis_data["image"].items():
            prompt_parts.append(f"- Image {idx}: {image_analysis}")
        prompt_parts.append("")

    # Process video content
    if "video" in analysis_data and analysis_data["video"]:
        prompt_parts.append("### Video Content:")
        for idx, video_analysis in analysis_data["video"].items():
            prompt_parts.append(f"- Video {idx}: {video_analysis}")
        prompt_parts.append("")

    return "\n".join(prompt_parts)


def _collect_all_items(dataset_path: str, max_users: int = None, skip_users: int = 0) -> tuple[List[Dict], List[str]]:
    """
    æ”¶é›†æ‰€æœ‰ç”¨æˆ·çš„æ‰€æœ‰itemä¿¡æ¯ï¼Œè·³è¿‡å·²å®Œæˆçš„ç”¨æˆ·

    Args:
        dataset_path: Path to dataset directory
        max_users: Maximum number of users to process (None for all users)
        skip_users: Number of users to skip from the beginning (default: 0)

    Returns:
        Tuple of:
        - List of item info dicts with user_id, item_type, item_name, item_path, etc.
        - List of skipped user IDs (users with existing user_profile.txt)
    """
    all_item_tasks = []
    skipped_users = []
    processed_users = 0

    # Get all user directories and sort them for consistent ordering
    all_users = [user for user in os.listdir(dataset_path) 
                 if os.path.isdir(os.path.join(dataset_path, user))]
    all_users.sort()  # Sort for consistent ordering

    # Skip the first N users if specified
    if skip_users > 0:
        all_users = all_users[skip_users:]
        print(f"â­ï¸  Skipping first {skip_users} users, starting from user {all_users[0] if all_users else 'N/A'}")

    for user in all_users:
        # Limit the number of users to process
        if max_users is not None and processed_users >= max_users:
            break

        user_dir = os.path.join(dataset_path, user)

        if not os.path.isdir(user_dir):
            continue

        # Check if user_profile.txt already exists - skip this user entirely
        user_profile_file = os.path.join(user_dir, "user_profile.txt")
        if os.path.exists(user_profile_file):
            print(f"â­ï¸  Skipping user {user} (user_profile.txt already exists)")
            skipped_users.append(user)
            continue

        # Increment processed users count (only count users that are actually processed)
        processed_users += 1

        # Process recommended items folder
        recommended_dir = os.path.join(user_dir, "recommended")
        if os.path.exists(recommended_dir):
            for item in os.listdir(recommended_dir):
                item_dir = os.path.join(recommended_dir, item)
                if os.path.isdir(item_dir):
                    all_item_tasks.append({
                        'user_id': user,
                        'item_type': 'recommended',
                        'item_name': item,
                        'item_path': item_dir
                    })

        # Process historical items folder
        historical_dir = os.path.join(user_dir, "historical")
        if os.path.exists(historical_dir):
            for item in os.listdir(historical_dir):
                item_dir = os.path.join(historical_dir, item)
                if os.path.isdir(item_dir):
                    all_item_tasks.append({
                        'user_id': user,
                        'item_type': 'historical',
                        'item_name': item,
                        'item_path': item_dir
                    })

        # Process validation items folder
        validation_dir = os.path.join(user_dir, "validation")
        if os.path.exists(validation_dir):
            for item in os.listdir(validation_dir):
                item_dir = os.path.join(validation_dir, item)
                if os.path.isdir(item_dir):
                    all_item_tasks.append({
                        'user_id': user,
                        'item_type': 'validation',
                        'item_name': item,
                        'item_path': item_dir
                    })

        # Process test items folder
        test_dir = os.path.join(user_dir, "test")
        if os.path.exists(test_dir):
            for item in os.listdir(test_dir):
                item_dir = os.path.join(test_dir, item)
                if os.path.isdir(item_dir):
                    all_item_tasks.append({
                        'user_id': user,
                        'item_type': 'test',
                        'item_name': item,
                        'item_path': item_dir
                    })

        # Handle legacy structure (items directly in user folder)
        for item in os.listdir(user_dir):
            item_dir = os.path.join(user_dir, item)

            # Skip if it's not a directory or if it's recommended/historical/validation/test folder
            if not os.path.isdir(item_dir) or item in ["recommended", "historical", "validation", "test"]:
                continue

            all_item_tasks.append({
                'user_id': user,
                'item_type': 'legacy',
                'item_name': item,
                'item_path': item_dir
            })

    return all_item_tasks, skipped_users

def _process_single_item_task(task: Dict, videoAnalyst, imageAnalyst, textAnalyst, item_mapping=None) -> Dict:
    """
    å¤„ç†å•ä¸ªitemä»»åŠ¡

    Args:
        task: åŒ…å«ç”¨æˆ·IDã€itemç±»å‹ã€itemåç§°å’Œè·¯å¾„çš„å­—å…¸
        item_mapping: Item IDåˆ°titleçš„æ˜ å°„å­—å…¸

    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    user_id = task['user_id']
    item_type = task['item_type']
    item_name = task['item_name']
    item_path = task['item_path']

    try:
        print(f"  ğŸ“ Processing {user_id}/{item_type}/{item_name}")

        # æ”¶é›†æ–‡ä»¶
        videos = []
        images = []
        text_list = []

        for file in os.listdir(item_path):
            file_type = get_file_type(file)
            if file_type == "video":
                videos.append(os.path.join(item_path, file))
            elif file_type == "image":
                images.append(os.path.join(item_path, file))
            elif file_type == "text":
                text_list.append(os.path.join(item_path, file))
            else:
                print(f"  âš ï¸  Unknown file type: {file}")
                continue

        # åˆ†ææ–‡ä»¶
        if videos:
            videoAnalyst(videos, item_path)
        if images:
            imageAnalyst(images, item_path)
        if text_list:
            textAnalyst(text_list, item_path)

        # è¯»å–åˆ†æç»“æœ
        analysis_file = os.path.join(item_path, "analysis.json")
        analysis_data = None
        if os.path.exists(analysis_file):
            try:
                with open(analysis_file, "r", encoding="utf-8") as f:
                    analysis_data = json.loads(f.read())
            except Exception as e:
                print(f"  âš ï¸  Error reading analysis file for {item_name}: {e}")

        # æ ¼å¼åŒ–ä¸ºprompt
        if analysis_data:
            formatted_prompt = format_analysis_to_prompt(analysis_data, item_name, item_mapping)
        elif videos or images or text_list:
            # å¦‚æœæ²¡æœ‰åˆ†ææ–‡ä»¶ä½†æœ‰æ–‡ä»¶ï¼Œåˆ›å»ºåŸºæœ¬ä¿¡æ¯
            item_title = _get_item_title(item_name, item_mapping)
            formatted_prompt = f"**Item: {item_title}**\n\nFiles found:\n- Videos: {len(videos)}\n- Images: {len(images)}\n- Texts: {len(text_list)}\n\nNote: Analysis in progress..."
        else:
            formatted_prompt = None

        result = {
            'user_id': user_id,
            'item_type': item_type,
            'item_name': item_name,
            'item_path': item_path,
            'formatted_prompt': formatted_prompt,
            'file_counts': {
                'videos': len(videos),
                'images': len(images),
                'texts': len(text_list)
            }
        }

        print(f"  âœ… Completed {user_id}/{item_type}/{item_name}: {len(videos)}v, {len(images)}i, {len(text_list)}t")
        return result

    except Exception as e:
        print(f"  âŒ Error processing {user_id}/{item_type}/{item_name}: {e}")
        return {
            'user_id': user_id,
            'item_type': item_type,
            'item_name': item_name,
            'error': str(e)
        }

def _process_single_user_profile(user_id: str, dataset_path: str, completed_tasks: List[Dict], userProfile) -> Dict:
    """
    Process a single user's profile generation

    Args:
        user_id: User ID (already real user ID, no conversion needed)
        dataset_path: Path to dataset directory
        completed_tasks: List of completed item analysis tasks
        userProfile: UserProfileGenerator instance

    Returns:
        Dict with processing results
    """
    try:
        print(f"\nğŸ  Processing user profile: {user_id}")
        user_dir = os.path.join(dataset_path, user_id)

        # Check if user_profile.txt already exists (skip to avoid redundant generation)
        user_profile_file = os.path.join(user_dir, "user_profile.txt")
        if os.path.exists(user_profile_file):
            print(f"â­ï¸  Skipping user {user_id} (user_profile.txt already exists)")
            return {
                'user_id': user_id,
                'status': 'skipped',
                'reason': 'user_profile_exists'
            }

        # è·å–æ—¶é—´é¡ºåº (user_id is already real_user_id, no conversion needed)
        chronological_order = get_chronological_order(user_id, convert_user_id=False)
        print(f"ğŸ“… Found {len(chronological_order)} items in chronological order for {user_id}")

        # æ”¶é›†è¿™ä¸ªç”¨æˆ·çš„æ‰€æœ‰ç»“æœ
        user_results = {
            'recommended': {},
            'historical': {},
            'validation': {},
            'test': {},
            'legacy': {}
        }

        for task_result in completed_tasks:
            if task_result['user_id'] == user_id and 'formatted_prompt' in task_result:
                item_type = task_result['item_type']
                item_name = task_result['item_name']
                formatted_prompt = task_result['formatted_prompt']

                if formatted_prompt:
                    user_results[item_type][item_name] = formatted_prompt

        # æŒ‰ç±»å‹ç»„ç»‡prompts
        recommended_prompts = list(user_results['recommended'].values())

        # Historical itemséœ€è¦æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
        historical_prompts = []
        if chronological_order:
            for item_id in chronological_order:
                if item_id in user_results['historical']:
                    historical_prompts.append(user_results['historical'][item_id])

            # æ·»åŠ ä¸åœ¨CSVä¸­çš„å†å²items
            for item, prompt in user_results['historical'].items():
                if item not in chronological_order:
                    historical_prompts.append(prompt)
        else:
            historical_prompts = list(user_results['historical'].values())

        # Legacy itemsä¹Ÿéœ€è¦æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
        legacy_prompts = []
        if chronological_order:
            for item_id in chronological_order:
                if item_id in user_results['legacy']:
                    legacy_prompts.append(user_results['legacy'][item_id])

            # æ·»åŠ ä¸åœ¨CSVä¸­çš„legacy items
            for item, prompt in user_results['legacy'].items():
                if item not in chronological_order:
                    legacy_prompts.append(prompt)
        else:
            legacy_prompts = list(user_results['legacy'].values())

        # ç»„åˆæ‰€æœ‰prompts (ä¸åŒ…å«validationå’Œtestæ•°æ®ï¼Œåªç”¨äºåˆ†æç»Ÿè®¡)
        dataset = os.getenv("DATASET", "unknown")
        sections = []

        if recommended_prompts:
            sections.append(f"## Recommended Items ({len(recommended_prompts)} items)\n\nThese are items recommended by the system for user {user_id} on the {dataset} platform.\n\n" + "\n---\n".join(recommended_prompts))

        if historical_prompts:
            sections.append(f"## Historical Interactions ({len(historical_prompts)} items)\n\nThese are items that user {user_id} has historically interacted with on the {dataset} platform, ordered chronologically from newest to oldest.\n\n" + "\n---\n".join(historical_prompts))

        if legacy_prompts:
            sections.append(f"## Legacy Items ({len(legacy_prompts)} items)\n\nThese items were processed using the legacy structure for user {user_id} on the {dataset} platform.\n\n" + "\n---\n".join(legacy_prompts))

        # æ³¨æ„ï¼švalidationå’Œtestæ•°æ®ä¸åŒ…å«åœ¨promptä¸­ï¼Œåªç”¨äºç»Ÿè®¡
        validation_count = len(user_results['validation'])
        test_count = len(user_results['test'])

        # åˆ›å»ºæœ€ç»ˆçš„item profileså†…å®¹
        if sections:
            item_profiles = f"# All Content Analysis for User {user_id}\n\n" + "\n\n".join(sections)
        else:
            item_profiles = f"# All Content Analysis for User {user_id}\n\nNo items found for analysis."

        # ä¿å­˜item profiles
        item_file = os.path.join(user_dir, "item_profiles.txt")
        with open(item_file, "w", encoding="utf-8") as f:
            f.write(item_profiles)

        print(f"âœ… Item profiles saved for {user_id}: {item_file}")
        print(f"   - Recommended items: {len(recommended_prompts)}")
        print(f"   - Historical items: {len(historical_prompts)}")
        print(f"   - Validation items: {validation_count} (analyzed but not included in profile)")
        print(f"   - Test items: {test_count} (analyzed but not included in profile)")
        print(f"   - Legacy items: {len(legacy_prompts)}")

        # ç”Ÿæˆç”¨æˆ·ç”»åƒ
        print(f"ğŸ§  Generating user profile for {user_id}...")
        user_profile = userProfile(item_profiles)
        user_file = os.path.join(user_dir, "user_profile.txt")
        with open(user_file, "w", encoding="utf-8") as f:
            f.write(user_profile)
        print(f"âœ… User profile saved for {user_id}: {user_file}")

        return {
            'user_id': user_id,
            'status': 'completed',
            'recommended_items': len(recommended_prompts),
            'historical_items': len(historical_prompts),
            'validation_items': validation_count,
            'test_items': test_count,
            'legacy_items': len(legacy_prompts),
            'total_items': len(recommended_prompts) + len(historical_prompts) + len(legacy_prompts)  # validationå’Œtestä¸è®¡å…¥totalï¼Œå› ä¸ºä¸ç”¨äºç”Ÿæˆprofile
        }

    except Exception as e:
        print(f"âŒ Error processing user profile for {user_id}: {e}")
        return {
            'user_id': user_id,
            'status': 'error',
            'error': str(e)
        }

def analyze(max_workers=15, user_profile_max_workers=15, max_users=None, skip_users=0):
    """
    ä½¿ç”¨æµæ°´çº¿å¼å¹¶å‘åˆ†ææ‰€æœ‰ç”¨æˆ·çš„æ•°æ®

    Pipeline strategy: å½“æŸä¸ªç”¨æˆ·çš„æ‰€æœ‰itemsåˆ†æå®Œæˆåï¼Œç«‹å³å¼€å§‹ç”Ÿæˆè¯¥ç”¨æˆ·çš„profile
    è¿™æ ·å¯ä»¥è®©itemåˆ†æå’Œuser profileç”Ÿæˆå¹¶è¡Œè¿›è¡Œï¼Œæé«˜æ•´ä½“æ•ˆç‡

    Args:
        max_workers: æœ€å¤§å¹¶å‘workeræ•°ï¼ˆç”¨äºitemåˆ†æï¼‰
        user_profile_max_workers: æœ€å¤§å¹¶å‘ç”¨æˆ·ç”»åƒç”Ÿæˆworkeræ•°
        max_users: æœ€å¤§å¤„ç†çš„ç”¨æˆ·æ•°é‡ï¼ˆNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰ç”¨æˆ·ï¼‰
        skip_users: è·³è¿‡å‰Nä¸ªç”¨æˆ·ï¼ˆé»˜è®¤0ï¼Œä»ç¬¬ä¸€ä¸ªç”¨æˆ·å¼€å§‹ï¼‰
    """
    print("ğŸš€ Starting pipelined analysis for all users...")
    if skip_users > 0:
        print(f"â­ï¸  Skipping first {skip_users} users")
    if max_users:
        print(f"ğŸ“Œ Processing next {max_users} users")
    print("=" * 60)

    dataset_path = os.path.join("download", os.getenv("DATASET"))

    if not os.path.exists(dataset_path):
        print(f"âŒ Dataset path not found: {dataset_path}")
        return

    # åˆå§‹åŒ–åˆ†æå™¨
    videoAnalyst = VideoAnalyst(max_workers=2, video_max_workers=3)
    imageAnalyst = ImageAnalyst(max_workers=3)
    textAnalyst = TextAnalyst(max_workers=3)
    userProfile = UserProfileGenerator()

    # åŠ è½½itemæ˜ å°„æ–‡ä»¶
    print("ğŸ“‹ Loading item mapping...")
    item_mapping = _load_item_mapping()

    # 1. æ”¶é›†æ‰€æœ‰itemä»»åŠ¡ï¼ˆè·³è¿‡å·²å®Œæˆçš„ç”¨æˆ·ï¼‰
    print("ğŸ“Š Collecting all item tasks...")
    all_item_tasks, skipped_users = _collect_all_items(dataset_path, max_users=max_users, skip_users=skip_users)

    if skipped_users:
        print(f"â­ï¸  Skipped {len(skipped_users)} users with existing user_profile.txt")

    if not all_item_tasks:
        print("âœ… No item tasks found (all users already processed)")
        return

    users = list(set(task['user_id'] for task in all_item_tasks))
    print(f"ğŸ“ˆ Found {len(all_item_tasks)} item tasks across {len(users)} users to process")

    # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„itemæ•°é‡
    user_item_counts = defaultdict(int)
    for task in all_item_tasks:
        user_item_counts[task['user_id']] += 1

    print(f"ğŸ“‹ User item counts: {dict(user_item_counts)}")

    # 2. ä½¿ç”¨æµæ°´çº¿å¼å¹¶å‘å¤„ç†
    print(f"ğŸ”„ Starting pipelined processing with {max_workers} item workers and {user_profile_max_workers} profile workers...")

    # è·Ÿè¸ªæ¯ä¸ªç”¨æˆ·çš„å®ŒæˆçŠ¶æ€
    user_completed_items = defaultdict(int)  # æ¯ä¸ªç”¨æˆ·å·²å®Œæˆçš„itemæ•°é‡
    user_tasks_dict = defaultdict(list)  # å­˜å‚¨æ¯ä¸ªç”¨æˆ·çš„completed tasks
    lock = Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨çš„æ“ä½œ

    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    completed_tasks = []
    user_profile_results = []
    user_profile_futures = {}  # å­˜å‚¨å·²æäº¤çš„user profileä»»åŠ¡

    # åˆ›å»ºä¸¤ä¸ªçº¿ç¨‹æ± ï¼šä¸€ä¸ªç”¨äºitemåˆ†æï¼Œä¸€ä¸ªç”¨äºuser profileç”Ÿæˆ
    item_executor = ThreadPoolExecutor(max_workers=max_workers)
    profile_executor = ThreadPoolExecutor(max_workers=user_profile_max_workers)

    try:
        # æäº¤æ‰€æœ‰itemä»»åŠ¡
        future_to_task = {
            item_executor.submit(_process_single_item_task, task, videoAnalyst, imageAnalyst, textAnalyst, item_mapping): task
            for task in all_item_tasks
        }

        # æ”¶é›†itemåˆ†æç»“æœï¼Œå¹¶åœ¨ç”¨æˆ·çš„itemså…¨éƒ¨å®Œæˆæ—¶è§¦å‘profileç”Ÿæˆ
        completed_item_count = 0
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            user_id = task['user_id']
            completed_item_count += 1

            try:
                result = future.result()

                with lock:
                    completed_tasks.append(result)
                    user_tasks_dict[user_id].append(result)
                    user_completed_items[user_id] += 1

                    current_completed = user_completed_items[user_id]
                    total_for_user = user_item_counts[user_id]

                    print(f"  âœ… [{completed_item_count}/{len(all_item_tasks)}] Completed item for user {user_id} ({current_completed}/{total_for_user})")

                    # æ£€æŸ¥è¯¥ç”¨æˆ·çš„æ‰€æœ‰itemsæ˜¯å¦éƒ½å®Œæˆäº†
                    if current_completed == total_for_user and user_id not in user_profile_futures:
                        # ç«‹å³æäº¤è¯¥ç”¨æˆ·çš„profileç”Ÿæˆä»»åŠ¡
                        print(f"  ğŸ¯ All items completed for user {user_id}, starting profile generation...")
                        profile_future = profile_executor.submit(
                            _process_single_user_profile,
                            user_id,
                            dataset_path,
                            user_tasks_dict[user_id],  # åªä¼ é€’è¯¥ç”¨æˆ·çš„tasks
                            userProfile
                        )
                        user_profile_futures[user_id] = profile_future

            except Exception as e:
                print(f"  âŒ [{completed_item_count}/{len(all_item_tasks)}] Error processing task: {e}")
                error_result = {
                    'user_id': task['user_id'],
                    'item_type': task['item_type'],
                    'item_name': task['item_name'],
                    'error': str(e)
                }

                with lock:
                    completed_tasks.append(error_result)
                    user_tasks_dict[user_id].append(error_result)
                    user_completed_items[user_id] += 1

                    current_completed = user_completed_items[user_id]
                    total_for_user = user_item_counts[user_id]

                    # å³ä½¿æœ‰é”™è¯¯ï¼Œä¹Ÿæ£€æŸ¥æ˜¯å¦è¯¥å¯åŠ¨profileç”Ÿæˆ
                    if current_completed == total_for_user and user_id not in user_profile_futures:
                        print(f"  ğŸ¯ All items processed for user {user_id} (with some errors), starting profile generation...")
                        profile_future = profile_executor.submit(
                            _process_single_user_profile,
                            user_id,
                            dataset_path,
                            user_tasks_dict[user_id],
                            userProfile
                        )
                        user_profile_futures[user_id] = profile_future

        # æ‰€æœ‰itemä»»åŠ¡å·²å®Œæˆ
        print(f"\nâœ… All item analysis completed!")
        print(f"â³ Waiting for {len(user_profile_futures)} user profile generation tasks to complete...\n")

        # æ”¶é›†æ‰€æœ‰user profileç»“æœ
        completed_profile_count = 0
        for user_id, future in user_profile_futures.items():
            completed_profile_count += 1
            try:
                result = future.result()
                user_profile_results.append(result)

                status_emoji = 'âœ…' if result['status'] == 'completed' else 'âŒ'
                print(f"  {status_emoji} [{completed_profile_count}/{len(user_profile_futures)}] User profile for {result['user_id']}: {result['status']}")

                if result['status'] == 'completed':
                    print(f"    ğŸ“Š Items - Recommended: {result['recommended_items']}, Historical: {result['historical_items']}, Validation: {result['validation_items']}, Test: {result['test_items']}, Legacy: {result['legacy_items']}")

            except Exception as e:
                print(f"  âŒ [{completed_profile_count}/{len(user_profile_futures)}] Error processing user profile for {user_id}: {e}")
                user_profile_results.append({
                    'user_id': user_id,
                    'status': 'error',
                    'error': str(e)
                })

    finally:
        # ç¡®ä¿å…³é—­çº¿ç¨‹æ± 
        item_executor.shutdown(wait=True)
        profile_executor.shutdown(wait=True)

    print("\n" + "=" * 60)
    print("ğŸ‰ Pipelined analysis completed for all users!")
    print(f"ğŸ“Š Summary:")
    print(f"  - Total users processed: {len(users)}")
    print(f"  - Total item tasks processed: {len(all_item_tasks)}")
    print(f"  - Successful item analyses: {len([r for r in completed_tasks if 'error' not in r])}")
    print(f"  - Failed item analyses: {len([r for r in completed_tasks if 'error' in r])}")
    print(f"  - Successful user profiles: {len([r for r in user_profile_results if r['status'] == 'completed'])}")
    print(f"  - Failed user profiles: {len([r for r in user_profile_results if r['status'] == 'error'])}")

    # è®¡ç®—æ€»çš„itemç»Ÿè®¡
    total_recommended = sum(r.get('recommended_items', 0) for r in user_profile_results if r['status'] == 'completed')
    total_historical = sum(r.get('historical_items', 0) for r in user_profile_results if r['status'] == 'completed')
    total_validation = sum(r.get('validation_items', 0) for r in user_profile_results if r['status'] == 'completed')
    total_test = sum(r.get('test_items', 0) for r in user_profile_results if r['status'] == 'completed')
    total_legacy = sum(r.get('legacy_items', 0) for r in user_profile_results if r['status'] == 'completed')

    print(f"ğŸ“ˆ Item Statistics:")
    print(f"  - Total recommended items: {total_recommended}")
    print(f"  - Total historical items: {total_historical}")
    print(f"  - Total validation items: {total_validation} (analyzed but not used for profile generation)")
    print(f"  - Total test items: {total_test} (analyzed but not used for profile generation)")
    print(f"  - Total legacy items: {total_legacy}")
    print(f"  - Items used for profile generation: {total_recommended + total_historical + total_legacy}")
    print(f"  - Grand total items analyzed: {total_recommended + total_historical + total_validation + total_test + total_legacy}")
    print("=" * 60)


