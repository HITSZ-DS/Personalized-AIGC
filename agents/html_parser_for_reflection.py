"""
HTML Parser for Reflection
è§£æç”Ÿæˆçš„HTMLæ–‡ä»¶ï¼Œç”Ÿæˆç”¨äºAIè¯„ä¼°çš„åºåˆ—åŒ–æ ¼å¼

æ”¯æŒä¸¤ç§ç±»å‹ï¼š
1. ITProduct (å°çº¢ä¹¦å›¾æ–‡): image_text.html
2. CommentProduct (è™æ‰‘è®¨è®º): discussion_post.html

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{text_0: "ç¬¬ä¸€æ®µæ–‡å­—å†…å®¹..."}
{image_0: "personalized_post_1.png"}  # å›¾ç‰‡è·¯å¾„ï¼Œä¾›å¤šæ¨¡æ€æ¨¡å‹å•ç‹¬åˆ†æ
{text_1: "ç¬¬äºŒæ®µæ–‡å­—å†…å®¹..."}
{link_0: "é“¾æ¥æ ‡é¢˜ | https://..."}

æ³¨æ„ï¼šå›¾ç‰‡åªä¿å­˜è·¯å¾„ï¼Œå®é™…åˆ†æç”±å¤šæ¨¡æ€æ¨¡å‹ï¼ˆGPT-4 Visionç­‰ï¼‰å•ç‹¬å¤„ç†
"""

import os
import base64
from pathlib import Path
from typing import List, Dict, Optional
from bs4 import BeautifulSoup


class HTMLParserForReflection:
    """è§£æHTMLä¸ºAIå¯è¯»çš„åºåˆ—æ ¼å¼"""
    
    def __init__(self):
        pass
    
    def parse_html_to_sequence(self, html_path: str) -> Dict:
        """
        è§£æHTMLæ–‡ä»¶ï¼Œç”Ÿæˆåºåˆ—åŒ–æ–‡æœ¬å’Œå›¾ç‰‡è·¯å¾„åˆ—è¡¨
        
        Args:
            html_path: HTMLæ–‡ä»¶è·¯å¾„
            
        Returns:
            {
                "sequence_text": "åºåˆ—åŒ–çš„æ–‡æœ¬å­—ç¬¦ä¸²",
                "image_paths": ["ç»å¯¹è·¯å¾„1", "ç»å¯¹è·¯å¾„2", ...],
                "stats": {"texts": N, "images": M, "links": K}
            }
        """
        html_path = Path(html_path)
        if not html_path.exists():
            raise FileNotFoundError(f"HTML file not found: {html_path}")
        
        # è¯»å–HTML
        with open(html_path, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f.read(), 'html.parser')
        
        # æå–å†…å®¹åºåˆ—
        content_div = soup.find('div', class_='post-content')
        if not content_div:
            return {
                "sequence_text": "Error: Could not find post-content div",
                "image_paths": [],
                "stats": {"texts": 0, "images": 0, "links": 0}
            }
        
        # ç”Ÿæˆåºåˆ—
        sequence_parts = []
        image_paths = []  # ä¿å­˜å›¾ç‰‡çš„ç»å¯¹è·¯å¾„
        text_idx = 0
        image_idx = 0
        link_idx = 0
        
        base_dir = html_path.parent
        
        for element in content_div.children:
            # 1. æ–‡æœ¬æ®µè½
            if element.name == 'p' or element.name == 'h2':
                text_content = element.get_text(strip=True)
                if text_content:
                    # æ¸…ç†markdownæ ‡è®°
                    text_content = self._clean_markdown(text_content)
                    sequence_parts.append(f"{{text_{text_idx}: \"{text_content}\"}}")
                    text_idx += 1
            
            # 2. å›¾ç‰‡ï¼ˆåªä¿å­˜è·¯å¾„ï¼Œä¸ç¼–ç base64ï¼‰
            elif element.name == 'div' and 'post-image' in element.get('class', []):
                img_tag = element.find('img')
                if img_tag and img_tag.get('src'):
                    img_src = img_tag['src']
                    img_path = base_dir / img_src
                    
                    if img_path.exists():
                        # åªä¿å­˜ç›¸å¯¹è·¯å¾„åˆ°åºåˆ—æ–‡æœ¬
                        sequence_parts.append(f"{{image_{image_idx}: \"{img_src}\"}}")
                        # ä¿å­˜ç»å¯¹è·¯å¾„ä¾›å¤šæ¨¡æ€æ¨¡å‹ä½¿ç”¨
                        image_paths.append(str(img_path.absolute()))
                        image_idx += 1
                    else:
                        sequence_parts.append(f"{{image_{image_idx}: \"[å›¾ç‰‡ä¸å­˜åœ¨: {img_src}]\"}}")
                        image_paths.append(None)
                        image_idx += 1
            
            # 3. é“¾æ¥
            elif element.name == 'a' and 'link-card' in element.get('class', []):
                title_tag = element.find('div', class_='link-title')
                title = title_tag.get_text(strip=True) if title_tag else "æœªçŸ¥é“¾æ¥"
                
                url = element.get('href', '#')
                
                link_text = f"{title} | {url}"
                sequence_parts.append(f"{{link_{link_idx}: \"{link_text}\"}}")
                link_idx += 1
        
        # æ‹¼æ¥ç»“æœ
        sequence_text = "\n".join(sequence_parts)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_line = f"\n\n[Statistics: {text_idx} texts, {image_idx} images, {link_idx} links]"
        sequence_text += stats_line
        
        return {
            "sequence_text": sequence_text,
            "image_paths": image_paths,
            "stats": {
                "texts": text_idx,
                "images": image_idx,
                "links": link_idx
            }
        }
    
    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„markdownæ ‡è®°"""
        import re
        # ç§»é™¤åŠ ç²—æ ‡è®° **text**
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        # ç§»é™¤å…¶ä»–markdownæ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        text = re.sub(r'__', '', text)
        return text


def test_parser():
    """æµ‹è¯•è§£æå™¨"""
    import sys
    
    print("="*80)
    print("ğŸ§ª æµ‹è¯• HTML Parser for Reflection")
    print("="*80)
    
    parser = HTMLParserForReflection()
    
    # æµ‹è¯•æ–‡ä»¶
    test_files = [
        ("generated_it/29_5726fe0950c4b401f76283be/image_text.html", "ITProduct"),
        ("generated_posts/3_132887808576185/discussion_post.html", "CommentProduct")
    ]
    
    for html_path, post_type in test_files:
        if not os.path.exists(html_path):
            print(f"\nâš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {html_path}")
            continue
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ æµ‹è¯•: {post_type}")
        print(f"   æ–‡ä»¶: {html_path}")
        print(f"{'='*80}")
        
        try:
            # è§£æHTMLï¼ˆåªä¿å­˜å›¾ç‰‡è·¯å¾„ï¼Œä¸å«base64ï¼‰
            print("\nç”ŸæˆAI Reflectionè¾“å…¥æ ¼å¼ï¼ˆå›¾ç‰‡ä»…ä¿å­˜è·¯å¾„ï¼‰")
            print("-"*80)
            result = parser.parse_html_to_sequence(html_path)
            
            sequence_text = result["sequence_text"]
            image_paths = result["image_paths"]
            stats = result["stats"]
            
            # åªæ‰“å°å‰1000å­—ç¬¦ç”¨äºé¢„è§ˆ
            print(sequence_text[:1000])
            if len(sequence_text) > 1000:
                print(f"\n... (æ€»å…± {len(sequence_text)} å­—ç¬¦ï¼Œå·²æˆªæ–­)")
            
            # ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š ç»Ÿè®¡: {stats['texts']} æ–‡æœ¬, {stats['images']} å›¾ç‰‡, {stats['links']} é“¾æ¥")
            
            # å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            if image_paths:
                print(f"\nğŸ–¼ï¸  å›¾ç‰‡è·¯å¾„åˆ—è¡¨:")
                for i, img_path in enumerate(image_paths):
                    if img_path:
                        print(f"   {i}. {img_path}")
                    else:
                        print(f"   {i}. [å›¾ç‰‡ç¼ºå¤±]")
            
        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*80}")
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("="*80)


if __name__ == "__main__":
    test_parser()

